{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57dee0b6",
   "metadata": {},
   "source": [
    "# Picking Algorithms\n",
    "\n",
    "In this exercise you get code snippets for two optimizations that fail silently. You need to fix them by selecting a different optimization algorithm. To make it a bit easier, we provide the criterion value at the optimum.\n",
    "\n",
    "If you find one that works, continue to search for one that works better. \n",
    "\n",
    "## Resources\n",
    "\n",
    "- [List of algorithms](https://estimagic.readthedocs.io/en/stable/algorithms.html)\n",
    "- [Documentation of algo_options](https://estimagic.readthedocs.io/en/stable/how_to_guides/optimization/how_to_specify_algorithm_and_algo_options.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1fcb3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import estimagic as em"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b50a918",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "\n",
    "This is a modified version of the `powell_singular` function from the More and Wild benchmark set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edced7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def powell_steps(x):\n",
    "    x = x.round(4)\n",
    "    fvec = np.zeros(4)\n",
    "    fvec[0] = x[0] + 10 * x[1]\n",
    "    fvec[1] = np.sqrt(5.0) * (x[2] - x[3])\n",
    "    fvec[2] = (x[1] - 2 * x[2]) ** 2\n",
    "    fvec[3] = np.sqrt(10.0) * (x[0] - x[3]) ** 2\n",
    "    out = {\"root_contributions\": fvec, \"value\": np.dot(fvec, fvec)}\n",
    "    return out\n",
    "\n",
    "powell_start = np.array([3, -1, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92ebf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal criterion value\n",
    "powell_criterion = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1ba89c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Minimize with 4 free parameters terminated successfully after 1 criterion evaluations, 1 derivative evaluations and 0 iterations.\n",
       "\n",
       "The value of criterion improved from 215.00000000000003 to 215.00000000000003.\n",
       "\n",
       "The scipy_lbfgsb algorithm reported: CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_powell = em.minimize(\n",
    "    criterion=powell_steps,\n",
    "    params=powell_start,\n",
    "    algorithm=\"scipy_lbfgsb\",\n",
    ")\n",
    "\n",
    "res_powell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca9f8b4",
   "metadata": {},
   "source": [
    "---\n",
    "The optimization thinks it terminated \"successfully\" but when you look at `res.params` you see that it actually got stuck at the start values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0517af36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3., -1.,  0.,  1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_powell.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c451d2",
   "metadata": {},
   "source": [
    "## Task 1:\n",
    "\n",
    "- Try to understand why the algorithm `scipy_lbfgsb` got stuck at the start parameters.\n",
    "- Find an algorithm that converges to the optimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f7a03e",
   "metadata": {},
   "source": [
    "## Solution 1:\n",
    "\n",
    "- The algorithm uses gradient information, however, because `powell_steps` rounds the input, the gradient is zero. Hence, it thinks it is at an optimum.\n",
    "- Use a gradient-free optimizer that utilizes the least-squares structure. (`nag_dfols`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82863097",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_powell = em.minimize(\n",
    "    criterion=powell_steps,\n",
    "    params=powell_start,\n",
    "    algorithm=\"nag_dfols\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad3df589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00476221, -0.00054761,  0.0022716 ,  0.00230015])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_powell.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3c09b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.1067145100000216e-08"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_powell.criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861c83e",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "This is the `bratu_2d` problem from the Cartis and Roberts benchmark set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "291166fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bratu(x):\n",
    "    alpha = 4.\n",
    "    x = x.reshape((int(np.sqrt(len(x))), int(np.sqrt(len(x)))))\n",
    "    p = x.shape[0] + 2\n",
    "    h = 1 / (p - 1)\n",
    "    c = alpha * h**2\n",
    "    xvec = np.zeros((x.shape[0] + 2, x.shape[1] + 2))\n",
    "    xvec[1 : x.shape[0] + 1, 1 : x.shape[1] + 1] = x\n",
    "    fvec = np.zeros_like(x)\n",
    "    for i in range(2, p):\n",
    "        for j in range(2, p):\n",
    "            fvec[i - 2, j - 2] = (\n",
    "                4 * xvec[i - 1, j - 1]\n",
    "                - xvec[i, j - 1]\n",
    "                - xvec[i - 2, j - 1]\n",
    "                - xvec[i - 1, j]\n",
    "                - xvec[i - 1, j - 2]\n",
    "                - c * np.exp(xvec[i - 1, j - 1])\n",
    "            )\n",
    "    fvec = fvec.flatten()\n",
    "    out = {\"root_contributions\": fvec, \"value\": np.dot(fvec, fvec)}\n",
    "    return out\n",
    "\n",
    "bratu_start = np.zeros(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b6fd517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal criterion value \n",
    "bratu_criterion = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8413eda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Minimize with 64 free parameters terminated unsuccessfully after 5000 criterion evaluations and 4697 iterations.\n",
       "\n",
       "The value of criterion improved from 0.1560737692424935 to 0.14373729795343512.\n",
       "\n",
       "The scipy_neldermead algorithm reported: Maximum number of function evaluations has been exceeded.\n",
       "\n",
       "Independent of the convergence criteria used by scipy_neldermead, the strength of convergence can be assessed by the following criteria:\n",
       "\n",
       "                             one_step     five_steps \n",
       "relative_criterion_change  0.0001292     0.0007854   \n",
       "relative_params_change       0.02281        0.0461   \n",
       "absolute_criterion_change  1.857e-05     0.0001129   \n",
       "absolute_params_change      0.002281       0.00461   \n",
       "\n",
       "(***: change <= 1e-10, **: change <= 1e-8, *: change <= 1e-5. Change refers to a change between accepted steps. The first column only considers the last step. The second column considers the last five steps.)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_bratu = em.minimize(\n",
    "    criterion=bratu,\n",
    "    params=bratu_start,\n",
    "    algorithm=\"scipy_neldermead\",\n",
    "    algo_options={\"stopping.max_criterion_evaluations\": 5000},\n",
    ")\n",
    "\n",
    "res_bratu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cbc4d9",
   "metadata": {},
   "source": [
    "---\n",
    "The optimization will terminate because it reaches the maximum number of criterion evaluations. Of course, you could increase that number even further, but you can do better! Also: One million evaluations would not even be enough!\n",
    "\n",
    "## Task 2:\n",
    "\n",
    "- Try to understand why `scipy_neldermead` does not converge on this problem.\n",
    "- Find an algorithm that converges to the optimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc83307",
   "metadata": {},
   "source": [
    "## Solution 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b10c9ab",
   "metadata": {},
   "source": [
    "- The algorithm `scipy_neldermead` does not use gradient information.\n",
    "- Use an algorithm that utilizes the gradient information. (`scipy_lbfgsb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa3e9928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Minimize with 64 free parameters terminated successfully after 41 criterion evaluations, 41 derivative evaluations and 36 iterations.\n",
       "\n",
       "The value of criterion improved from 0.1560737692424935 to 1.7033175395306e-10.\n",
       "\n",
       "The scipy_lbfgsb algorithm reported: CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\n",
       "\n",
       "Independent of the convergence criteria used by scipy_lbfgsb, the strength of convergence can be assessed by the following criteria:\n",
       "\n",
       "                             one_step     five_steps \n",
       "relative_criterion_change  2.448e-09**   1.652e-07*  \n",
       "relative_params_change     6.455e-05      0.002428   \n",
       "absolute_criterion_change  2.448e-10**   1.652e-08*  \n",
       "absolute_params_change     1.675e-05      0.000642   \n",
       "\n",
       "(***: change <= 1e-10, **: change <= 1e-8, *: change <= 1e-5. Change refers to a change between accepted steps. The first column only considers the last step. The second column considers the last five steps.)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_bratu = em.minimize(\n",
    "    criterion=bratu,\n",
    "    params=bratu_start,\n",
    "    algorithm=\"scipy_lbfgsb\",\n",
    ")\n",
    "\n",
    "res_bratu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
